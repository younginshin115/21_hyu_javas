{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"워드 임베딩 스터디_Word2Vec실습.ipynb","provenance":[],"mount_file_id":"1ENtYgZ-9Pc8yRAAF69OkmP79j4FPv6MX","authorship_tag":"ABX9TyONcW5Z1264CdxMB+JH1PBw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jgA0Y7SvFZ4R"},"source":["#  1. 영어 Word2Vec 만들기"]},{"cell_type":"code","metadata":{"id":"4Ec1vhZtBcrs"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84_i4TwhFtOL"},"source":["import urllib.request\n","import zipfile\n","from lxml import etree\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qUmu6MQFwlC"},"source":["# 훈련데이터 이해하기"]},{"cell_type":"code","metadata":{"id":"f6Aa6lyqFuaR"},"source":["# XML데이터이므로 전처리 필요\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4KvKkbtZGRAJ"},"source":["# 훈련데이터 전처리하기"]},{"cell_type":"code","metadata":{"id":"fx4PjxffFzDK"},"source":["targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","target_text = etree.parse(targetXML)\n","\n","# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n","# 해당 코드는 괄호로 구성된 내용을 제거.\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","\n","# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","sent_text = sent_tokenize(content_text)\n","\n","# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","\n","# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n","result = [word_tokenize(sentence) for sentence in normalized_text]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btWbzFnHGmCh"},"source":["print('총 샘플의 개수 : {}'.format(len(result)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_vfOC4iGmWm"},"source":["# 샘플 3개만 출력\n","for line in result[:3]:\n","    print(line)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"viIxawwKGrtD"},"source":["# Word2Vec 훈련시키기"]},{"cell_type":"code","metadata":{"id":"7BIqbkMZGt7g"},"source":["from gensim.models import Word2Vec\n","model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n","# 만약 TypeError: __init__() got an unexpected keyword argument 'size' 라는 에러 발생 시에는\n","# size 대신 vector_size로 바꿔서 적어주세요."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_P5HT3cHLA_"},"source":["model_result = model.wv.most_similar(\"man\")\n","print(model_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Oo-2nuPHRfR"},"source":["# Word2Vec 모델 저장하고 로드하기"]},{"cell_type":"code","metadata":{"id":"Y-gzaNCjHMyw"},"source":["from gensim.models import KeyedVectors\n","model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n","loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjo1usinHYEQ"},"source":["model_result = loaded_model.most_similar(\"man\")\n","print(model_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYnRdqOTHZYg"},"source":["#  2. 한국어 Word2Vec 만들기(네이버 영화 리뷰)"]},{"cell_type":"code","metadata":{"id":"v2erWq1AHmwZ"},"source":["pip install konlpy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Od6FsgktHe4Q"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import urllib.request\n","from gensim.models.word2vec import Word2Vec\n","from konlpy.tag import Okt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svNpzhK6IBC3"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/NLP_Classification/sentiment/Cleaned Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2rkxbWaIstw"},"source":["import json\n","with open('KoNLPy(Mecab)_stopwords(18)_Total(movie&shopping&game&target)_tokened_vocab_v0.1.json', encoding='UTF8') as json_file:\n","    tokenized_data = json.load(json_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eL2PgkD2Hyqn"},"source":["print(len(tokenized_data))\n","tokenized_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKIWKZzsJLeQ"},"source":["# 리뷰 길이 분포 확인\n","print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n","print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n","plt.hist([len(s) for s in tokenized_data], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzIwdSeJJWWI"},"source":["from gensim.models import Word2Vec\n","model = Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIKPDElbJjk5"},"source":["# 완성된 임베딩 매트릭스의 크기 확인\n","model.wv.vectors.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TZNv2rlKeDQ"},"source":["from gensim.models import KeyedVectors\n","model.wv.save_word2vec_format('kor_w2v') # 모델 저장"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvnkKb3RJlQI"},"source":["print(model.wv.most_similar(\"최민식\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZb5067JJnGq"},"source":["print(model.wv.most_similar(\"히어로\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zZ0uVRuJnif"},"source":["print(model.wv.most_similar(\"꺼져\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mu_dymnkJpDD"},"source":["print(model.wv.most_similar(\"짱\"))"],"execution_count":null,"outputs":[]}]}