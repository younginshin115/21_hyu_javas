{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"워드 임베딩 스터디_Word2Vec실습2.ipynb","provenance":[],"mount_file_id":"1mB5MPuLxRA7IIcy3j-OTi6kBl2H-NxLp","authorship_tag":"ABX9TyMW1eFO/9bucOaaYnzizImF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jgA0Y7SvFZ4R"},"source":["#  1. 영어 Word2Vec 만들기"]},{"cell_type":"code","metadata":{"id":"4Ec1vhZtBcrs"},"source":["import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84_i4TwhFtOL"},"source":["import urllib.request\n","import zipfile\n","from lxml import etree\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qUmu6MQFwlC"},"source":["# 훈련데이터 이해하기"]},{"cell_type":"code","metadata":{"id":"f6Aa6lyqFuaR"},"source":["# XML데이터이므로 전처리 필요\n","urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4KvKkbtZGRAJ"},"source":["# 훈련데이터 전처리하기"]},{"cell_type":"code","metadata":{"id":"fx4PjxffFzDK"},"source":["targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","target_text = etree.parse(targetXML)\n","\n","# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n","# 해당 코드는 괄호로 구성된 내용을 제거.\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n","\n","# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","sent_text = sent_tokenize(content_text)\n","\n","# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","     normalized_text.append(tokens)\n","\n","# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n","result = [word_tokenize(sentence) for sentence in normalized_text]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"btWbzFnHGmCh"},"source":["print('총 샘플의 개수 : {}'.format(len(result)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_vfOC4iGmWm"},"source":["# 샘플 3개만 출력\n","for line in result[:3]:\n","    print(line)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"viIxawwKGrtD"},"source":["# Word2Vec 훈련시키기"]},{"cell_type":"code","metadata":{"id":"7BIqbkMZGt7g"},"source":["from gensim.models import Word2Vec\n","model = Word2Vec(sentences=result, size=100, window=5, min_count=5, workers=4, sg=0)\n","# 만약 TypeError: __init__() got an unexpected keyword argument 'size' 라는 에러 발생 시에는\n","# size 대신 vector_size로 바꿔서 적어주세요."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_P5HT3cHLA_"},"source":["model_result = model.wv.most_similar(\"man\")\n","print(model_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Oo-2nuPHRfR"},"source":["# Word2Vec 모델 저장하고 로드하기"]},{"cell_type":"code","metadata":{"id":"Y-gzaNCjHMyw"},"source":["from gensim.models import KeyedVectors\n","model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n","loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjo1usinHYEQ"},"source":["model_result = loaded_model.most_similar(\"man\")\n","print(model_result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PYnRdqOTHZYg"},"source":["#  2. 한국어 Word2Vec 만들기(토탈훈련데이터)"]},{"cell_type":"code","metadata":{"id":"v2erWq1AHmwZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628064044189,"user_tz":-540,"elapsed":7329,"user":{"displayName":"맹광국","photoUrl":"","userId":"00860531964279012518"}},"outputId":"0f84fdf3-6b00-4d2c-dfc5-70d0ccd133a6"},"source":["pip install konlpy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 6.0 MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 58.8 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Od6FsgktHe4Q","executionInfo":{"status":"ok","timestamp":1628064045856,"user_tz":-540,"elapsed":1671,"user":{"displayName":"맹광국","photoUrl":"","userId":"00860531964279012518"}}},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import urllib.request\n","from gensim.models.word2vec import Word2Vec\n","from konlpy.tag import Okt"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"svNpzhK6IBC3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628064273985,"user_tz":-540,"elapsed":687,"user":{"displayName":"맹광국","photoUrl":"","userId":"00860531964279012518"}},"outputId":"cf6bcba1-0ea6-4877-e630-f0fc1aa2ead7"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/NLP_Classification/sentiment/Cleaned Dataset"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/NLP_Classification/sentiment/Cleaned Dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X2rkxbWaIstw"},"source":["import json\n","with open('KoNLPy(Mecab)_stopwords(18)_Total(movie&shopping&game&target)_tokened_vocab_v0.1.json', encoding='UTF8') as json_file:\n","    tokenized_data = json.load(json_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eL2PgkD2Hyqn"},"source":["print(len(tokenized_data))\n","tokenized_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PKIWKZzsJLeQ"},"source":["# 리뷰 길이 분포 확인\n","print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n","print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n","plt.hist([len(s) for s in tokenized_data], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DzIwdSeJJWWI"},"source":["from gensim.models import Word2Vec\n","model = Word2Vec(sentences = tokenized_data, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIKPDElbJjk5"},"source":["# 완성된 임베딩 매트릭스의 크기 확인\n","model.wv.vectors.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TZNv2rlKeDQ"},"source":["from gensim.models import KeyedVectors\n","model.wv.save_word2vec_format('kor_w2v') # 모델 저장"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gvnkKb3RJlQI"},"source":["print(model.wv.most_similar(\"최민식\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZb5067JJnGq"},"source":["print(model.wv.most_similar(\"히어로\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zZ0uVRuJnif"},"source":["print(model.wv.most_similar(\"꺼져\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mu_dymnkJpDD"},"source":["print(model.wv.most_similar(\"짱\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ui1ueGQLUxH"},"source":["#  3. 한국어 Word2Vec 만들기(위키피디아)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6na-xC6nMoHH","executionInfo":{"status":"ok","timestamp":1628064380888,"user_tz":-540,"elapsed":282,"user":{"displayName":"맹광국","photoUrl":"","userId":"00860531964279012518"}},"outputId":"5909505f-cbf3-4e1c-bade-d6ccfc697115"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/NLP_Classification/sentiment/Cleaned Dataset/Word2Vec"],"execution_count":12,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/NLP_Classification/sentiment/Cleaned Dataset/Word2Vec\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"niVTCuYqL-VI"},"source":["1) 위키피디아 한국어 덤프 파일 다운로드\n","\n","https://dumps.wikimedia.org/kowiki/latest/\n","\n","kowiki-latest-pages-articles.xml.bz2 "]},{"cell_type":"markdown","metadata":{"id":"2QNqXj_aMIvR"},"source":["2) 위키피디아 익스트랙터 다운로드"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCex83yLMCoh","executionInfo":{"status":"ok","timestamp":1628064369922,"user_tz":-540,"elapsed":288,"user":{"displayName":"맹광국","photoUrl":"","userId":"00860531964279012518"}},"outputId":"34234ea0-1f6f-4865-b229-d84032103f1f"},"source":["!git clone \"https://github.com/attardi/wikiextractor.git\"  "],"execution_count":11,"outputs":[{"output_type":"stream","text":["fatal: destination path 'wikiextractor' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EbfsMLcQMbpW"},"source":["3) 위키피디아 한국어 덤프 파일 변환"]},{"cell_type":"code","metadata":{"id":"q0DTyncbMBwh"},"source":["python WikiExtractor.py kowiki-latest-pages-articles.xml.bz2  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_1q1GjcLURA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7cnU-SfNBCI"},"source":["# 4) 훈련 데이터 만들기"]},{"cell_type":"code","metadata":{"id":"HXTGqnjUNEDX"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EUykMhxNDV_"},"source":["copy AA디렉토리의 경로\\wiki* wikiAA.txt"]}]}