version: "3.2"
services:
  spark-master:
    image: merolhack/spark:latest
    container_name: spark-master
    hostname: spark-master
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
      - "7077:7077"
#    networks:
#      - spark-network
    environment:
      - "SPARK_LOCAL_IP=spark-master"
      - "SPARK_MASTER_PORT=7077"
      - "SPARK_MASTER_WEBUI_PORT=8080"
    command: "/start-master.sh"
  spark-worker:
    image: merolhack/spark:latest
    depends_on:
      - spark-master
    ports:
      - 8080
#    networks:
#      - spark-network
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "SPARK_WORKER_WEBUI_PORT=8080"
    command: "/start-worker.sh"
   
  kafka:
    image: kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "test123:1:1"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  dash_app:
     container_name: dash_app
     restart: always
     build: ./dash_app
     ports:
       - "8000:8000"
     command: gunicorn -w 1 -b :8000 app:server

   nginx:
     container_name: nginx
     restart: always
     build: ./nginx
     ports:
       - "80:80"
     depends_on:
       - dash_app
        
#networks:
#  spark-network:
#    driver: bridge
#    ipam:
#      driver: default 
 
